{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kate/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. With graph execution (i.e. without eager execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow programs have two halves: definig the graph, and opening a session to run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first half of the script looks like this:\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-22ef489a67e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# second half of the script looks like this:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1033\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1036\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "# second half of the script looks like this:\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer) # note that you need to initialise your tf.Variables\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, equivalently, like this:\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    #result = f.eval()  # why is this not result = sess.run(f)?\n",
    "    result = sess.run(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's going on?\n",
    "\n",
    "*Variables*\n",
    "`tf.Variable` objects store mutable `tf.Tensor` values accessed during training to make automatic differentiation easier. The parameters of a model can be set as variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With eager execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager execution is good for:\n",
    "\n",
    "* debugging\n",
    "* beginners: you use Python control flow, instead of a graph structure\n",
    "\n",
    "However, deploying code written for eager execution is more difficult: you should either generate a graph from the model, or run the Python runtime and code directly on the server.\n",
    "\n",
    "\n",
    "With graph execution, program state (such as the variables) gets stored as globals. Its lifetime is managed by the `tf.Session` object that contains the execution. In contrast, during eager execution the lifetime of state objects is determined by the lifetime of their corresponding Python object.\n",
    "\n",
    "To use eager execution, you have to explicitly enable it with `tf.enable_eager_execution()`. This needs to be done right at program startup, so we'll do it in another notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is an API on top of Tensorflow. It is intended to be user-friendly, human-readable, etc.\n",
    "\n",
    "It's worth understanding Keras before trying to use eager execution, because eager execution works well with `tf.keras` \n",
    "\n",
    "Google has adopted Keras as an interface to Tensorflow. Note that `tf.keras` is not exactly the same as Keras, but Keras was, on adoption, merged into Tensorflow. Just do `from tensorflow import keras`\n",
    "\n",
    "Keras docs: https://keras.io/#guiding-principles\n",
    "Tensoflow on Keras: https://www.tensorflow.org/guide/keras\n",
    "\n",
    "In Keras, you assemble layers to build models. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the `tf.keras.Sequential` model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can define your model. It needs a kind (eg Sequential) and then some layers (here densely connected layers)\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **There are many `tf.keras.layers`.**\n",
    "\n",
    "\n",
    "* There are also many kinds of _construction parameter_ to pass to the layers on creation. eg:\n",
    "\n",
    "\n",
    " * `activation`: Set the activation function for the layer. By default, no activation is applied.\n",
    "\n",
    "\n",
    " * `kernel_initializer` and `bias_initializer`: The initialization schemes that create the layer's weights (kernel and bias). This parameter is a name or a callable object. This defaults to the \"Glorot uniform\" initializer. That'll probably do for us.\n",
    "\n",
    "\n",
    " * `kernel_regularizer` and `bias_regularizer`: The regularization schemes that apply the layer's weights (kernel and bias), such as `L1` or `L2` regularization. By default, no regularization is applied.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model is just a simple stack of layers, then instantiate it as a `Sequential` model. Easy.\n",
    "\n",
    "On the other hand, if your model is more complicated -- multi-input or multi-output -- then use the Keras Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then train your model by calling .compile()\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tf.keras.Model.compile takes three important arguments -- optimizer! loss! metrics!**\n",
    "\n",
    "\n",
    "\n",
    " * `optimizer`: This object specifies the training procedure. Pass it optimizer instances from the `tf.train` module, such as `AdamOptimizer`, `RMSPropOptimizer`, or `GradientDescentOptimizer`.\n",
    "\n",
    "\n",
    "* `loss`: The function to minimize during optimization. Common choices include mean square error (`mse`), `categorical_crossentropy`, and `binary_crossentropy`. Loss functions are specified by name or by passing a callable object from the `tf.keras.losses` module.\n",
    "\n",
    "\n",
    "* `metrics`: Used to monitor training. These are string names or callables from the `tf.keras.metrics` module.\n",
    "\n",
    "\n",
    "\n",
    "e.g.\n",
    "\n",
    "    # Configure a model for mean-squared error regression.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "                  loss='mse',       # mean squared error\n",
    "                  metrics=['mae'])  # mean absolute error\n",
    "\n",
    "    # Configure a model for categorical classification.\n",
    "    model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=[keras.metrics.categorical_accuracy])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it some data! \n",
    "\n",
    "For small models, you can use `numpy` arrays in memory.\n",
    "For large models, you can use the `Datasets` API.\n",
    "\n",
    "\n",
    "* **`tf.keras.Model.fit` takes three important arguments:** \n",
    "\n",
    "\n",
    "* `epochs`: Training is structured into epochs. An epoch is one iteration over the entire input data (this is done in smaller batches).\n",
    "\n",
    "\n",
    "* `batch_size`: When passed NumPy data, the model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch. Be aware that the last batch may be smaller if the total number of samples is not divisible by the batch size.\n",
    "\n",
    "\n",
    "* `validation_data`: When prototyping a model, you want to easily monitor its performance on some validation data. Passing this argument — a tuple of inputs and labels — allows the model to display the loss and metrics in inference mode for the passed data, at the end of each `epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.6576 - acc: 0.1006 - val_loss: 11.7940 - val_acc: 0.1300\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.6245 - acc: 0.1045 - val_loss: 11.7867 - val_acc: 0.1200\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.6173 - acc: 0.1338 - val_loss: 11.7871 - val_acc: 0.1200\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.6128 - acc: 0.1270 - val_loss: 11.7867 - val_acc: 0.1500\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.6087 - acc: 0.1279 - val_loss: 11.7905 - val_acc: 0.0700\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.6037 - acc: 0.1396 - val_loss: 11.7940 - val_acc: 0.1200\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.5991 - acc: 0.1523 - val_loss: 11.7959 - val_acc: 0.0700\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.5953 - acc: 0.1523 - val_loss: 11.8001 - val_acc: 0.0900\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.5908 - acc: 0.1543 - val_loss: 11.8044 - val_acc: 0.0500\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.5856 - acc: 0.1719 - val_loss: 11.8029 - val_acc: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb29ce2c18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate and predict!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with `tf.keras.Model.evaluate`. Predict with `tf.keras.Model.predict`.\n",
    "\n",
    "Both of these methods can use both NumPy data (fine if a small model) and a `tf.data.Dataset` (advised if a big model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x, y, batch_size=32) # for small model\n",
    "\n",
    "# model.evaluate(dataset, steps=30) # for large model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "You should also probably be aware that Keras runs just fine in a distributed manner. The story is basically the same as for TensorFlow more generally.\n",
    "\n",
    "`tf.keras` models can run on multiple GPUs using `tf.contrib.distribute.DistributionStrategy`. This API provides distributed training on multiple GPUs with almost no changes to existing code.\n",
    "\n",
    "There are a few distribution strategies -- synchronous and asynchoronous parameter parallelism, and model parallelism. Mirrored Strategy is one synchronous parameter parallel strategy. It is the only distribution strategy currently supported by `tf.keras`.\n",
    "\n",
    "To use DistributionStrategy with Keras, convert the `tf.keras.Model` to a `tf.estimator.Estimator` with `tf.keras.estimator.model_to_estimator`, then train the estimator. Then add another line or two but its not (in theory) too hard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
